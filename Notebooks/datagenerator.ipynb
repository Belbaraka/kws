{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attempt in thisto create a vanilla end to end ASR model with CTC loss using keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.insert(1, os.path.abspath('../models'))\n",
    "import data_preparation \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(os.path.join(path2features, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(591, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2data = os.path.abspath('../../Datasets/tedlium/TEDLIUM_release1')\n",
    "path2features = os.path.abspath('../../Datasets/dev_mfcc')\n",
    "filename = 'ids_labels.p'\n",
    "n_mfcc = 26\n",
    "n_mels = 40\n",
    "hop_length = 160\n",
    "frame_length = 320\n",
    "batch_size = 32\n",
    "epoch_length = 0\n",
    "shuffle = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_params = {'path2data': path2data,\n",
    "                    'path2features': path2features,\n",
    "                    'pickle_filename': filename,\n",
    "                    'n_mfcc': n_mfcc,\n",
    "                    'n_mels': n_mels,\n",
    "                    'hop_length': hop_length,\n",
    "                    'frame_length': frame_length\n",
    "                    }\n",
    "\n",
    "data_prep = data_preparation.DataPrep(**data_prep_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep.process_tedelium(category='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_params = {'path2features': path2features,\n",
    "                         'pickle_filename': filename,\n",
    "                         'batch_size': batch_size,\n",
    "                         'mfcc_features': n_mfcc,\n",
    "                         'epoch_length': epoch_length,\n",
    "                         'shuffle': shuffle\n",
    "                        }\n",
    "\n",
    "data_gen = data_preparation.DataGenerator(**data_generator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, CuDNNLSTM, Bidirectional, TimeDistributed, Conv1D, ZeroPadding1D\n",
    "from keras.layers import Lambda, Input, Dropout, Masking\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda implementation of CTC loss, using ctc_batch_cost from TensorFlow backend\n",
    "# CTC implementation from Keras example found at https://github.com/keras-team/keras/blob/master/examples/image_ocr.py\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    # print \"y_pred_shape: \", y_pred.shape\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    # print \"y_pred_shape: \", y_pred.shape\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "\n",
    "# Returns clipped relu, clip value set to 20.\n",
    "def clipped_relu(value):\n",
    "    return K.relu(value, max_value=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_rnn(units, input_dim=26, output_dim=29, dropout=0.2, numb_of_dense=1, n_layers=1):\n",
    "    \"\"\"\n",
    "    :param units: Hidden units per layer\n",
    "    :param input_dim: Size of input dimension (number of features), default=26\n",
    "    :param output_dim: Output dim of final layer of model (input to CTC layer), default=29\n",
    "    :param dropout: Dropout rate, default=0.2\n",
    "    :param numb_of_dense: Number of fully connected layers before recurrent, default=3\n",
    "    :param n_layers: Number of simple RNN layers, default=3\n",
    "    :return: network_model: deep_rnn\n",
    "    Default model contains:\n",
    "     1 layer of masking\n",
    "     3 layers of fully connected clipped ReLu (DNN) with dropout 20 % between each layer\n",
    "     3 layers of RNN with 20% dropout\n",
    "     1 layers of fully connected clipped ReLu (DNN) with dropout 20 % between each layer\n",
    "     1 layer of softmax\n",
    "    \"\"\"\n",
    "\n",
    "    # Input data type\n",
    "    dtype = 'float32'\n",
    "\n",
    "    # Kernel and bias initializers for fully connected dense layers\n",
    "    kernel_init_dense = 'random_normal'\n",
    "    bias_init_dense = 'random_normal'\n",
    "\n",
    "    # Kernel and bias initializers for recurrent layer\n",
    "    kernel_init_rnn = 'glorot_uniform'\n",
    "    bias_init_rnn = 'zeros'\n",
    "\n",
    "    # ---- Network model ----\n",
    "    # x_input layer, dim: (batch_size * x_seq_size * mfcc_features)\n",
    "    input_data = Input(name='the_input',shape=(None, input_dim), dtype=dtype)\n",
    "\n",
    "    # Masking layer\n",
    "    x = Masking(mask_value=0., name='masking')(input_data)\n",
    "\n",
    "    # Default 3 fully connected layers DNN ReLu\n",
    "    # Default dropout rate 20 % at each FC layer\n",
    "    for i in range(0, numb_of_dense):\n",
    "        x = TimeDistributed(Dense(units=units, kernel_initializer=kernel_init_dense, bias_initializer=bias_init_dense,\n",
    "                                  activation=clipped_relu), name='fc_'+str(i+1))(x)\n",
    "        x = TimeDistributed(Dropout(dropout), name='dropout_'+str(i+1))(x)\n",
    "\n",
    "    # Deep RNN network with a default of 3 layers\n",
    "    for i in range(0, n_layers):\n",
    "        x = SimpleRNN(units, activation='relu', kernel_initializer=kernel_init_rnn, bias_initializer=bias_init_rnn,\n",
    "                      dropout=dropout, return_sequences=True, name=('deep_rnn_'+ str(i+1)))(x)\n",
    "\n",
    "    # 1 fully connected layer DNN ReLu with default 20% dropout\n",
    "    x = TimeDistributed(Dense(units=units, kernel_initializer=kernel_init_dense, bias_initializer=bias_init_dense,\n",
    "                              activation='relu'), name='fc_4')(x)\n",
    "    x = TimeDistributed(Dropout(dropout), name='dropout_4')(x)\n",
    "\n",
    "    # Output layer with softmax\n",
    "    y_pred = TimeDistributed(Dense(units=output_dim, kernel_initializer=kernel_init_dense,\n",
    "                                   bias_initializer=bias_init_dense, activation='softmax'), name='softmax')(x)\n",
    "\n",
    "    # ---- CTC ----\n",
    "    # y_input layers (transcription data) for CTC loss\n",
    "    labels = Input(name='the_labels', shape=[None], dtype=dtype)        # transcription data (batch_size * y_seq_size)\n",
    "    input_length = Input(name='input_length', shape=[1], dtype=dtype)   # unpadded len of all x_sequences in batch\n",
    "    label_length = Input(name='label_length', shape=[1], dtype=dtype)   # unpadded len of all y_sequences in batch\n",
    "\n",
    "    # Lambda layer with ctc_loss function due to Keras not supporting CTC layers\n",
    "    loss_out = Lambda(function=ctc_lambda_func, name='ctc', output_shape=(1,))(\n",
    "                      [y_pred, labels, input_length, label_length])\n",
    "\n",
    "    network_model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    return network_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blstm(units, input_dim=26, output_dim=29, dropout=0.2, numb_of_dense=3, cudnn=False, n_layers=1):\n",
    "    \"\"\"\n",
    "    :param units: Hidden units per layer\n",
    "    :param input_dim: Size of input dimension (number of features), default=26\n",
    "    :param output_dim: Output dim of final layer of model (input to CTC layer), default=29\n",
    "    :param dropout: Dropout rate, default=0.2\n",
    "    :param numb_of_dense: Number of fully connected layers before recurrent, default=3\n",
    "    :param cudnn: Whether to use the CuDNN optimized LSTM (GPU only), default=False\n",
    "    :param n_layers: Number of stacked BLSTM layers, default=1\n",
    "    :return: network_model: blstm\n",
    "    Default model contains:\n",
    "     1 layer of masking\n",
    "     3 layers of fully connected clipped ReLu (DNN) with dropout 20 % between each layer\n",
    "     1 layer of BLSTM\n",
    "     1 layers of fully connected clipped ReLu (DNN) with dropout 20 % between each layer\n",
    "     1 layer of softmax\n",
    "    \"\"\"\n",
    "\n",
    "    # Input data type\n",
    "    dtype = 'float32'\n",
    "\n",
    "    # Kernel and bias initializers for fully connected dense layers\n",
    "    kernel_init_dense = 'random_normal'\n",
    "    bias_init_dense = 'random_normal'\n",
    "\n",
    "    # Kernel and bias initializers for recurrent layer\n",
    "    kernel_init_rnn = 'glorot_uniform'\n",
    "    bias_init_rnn = 'random_normal'\n",
    "\n",
    "    # ---- Network model ----\n",
    "    # x_input layer, dim: (batch_size * x_seq_size * features)\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim), dtype=dtype)\n",
    "\n",
    "    if cudnn:\n",
    "        # CuDNNLSTM does not support masking\n",
    "        x = input_data\n",
    "    else:\n",
    "        # Masking layer\n",
    "        x = Masking(mask_value=0., name='masking')(input_data)\n",
    "\n",
    "    # Default 3 fully connected layers DNN ReLu\n",
    "    # Default dropout rate 20 % at each FC layer\n",
    "    for i in range(0, numb_of_dense):\n",
    "        x = TimeDistributed(Dense(units=units, kernel_initializer=kernel_init_dense, bias_initializer=bias_init_dense,\n",
    "                                  activation=clipped_relu), name='fc_'+str(i+1))(x)\n",
    "        x = TimeDistributed(Dropout(dropout), name='dropout_'+str(i+1))(x)\n",
    "\n",
    "    # Bidirectional RNN (with ReLu)\n",
    "    # If running on GPU, use the CuDNN optimised LSTM model\n",
    "    if cudnn:\n",
    "        for i in range(0, n_layers):\n",
    "            x = Bidirectional(CuDNNLSTM(units, kernel_initializer=kernel_init_rnn, bias_initializer=bias_init_rnn,\n",
    "                                        unit_forget_bias=True, return_sequences=True),\n",
    "                              merge_mode='sum', name=('CuDNN_bi_lstm' + str(i+1)))(x)\n",
    "    else:\n",
    "        for i in range(0, n_layers):\n",
    "            x = Bidirectional(LSTM(units, activation='relu', kernel_initializer=kernel_init_rnn, dropout=dropout,\n",
    "                                   bias_initializer=bias_init_rnn, return_sequences=True),\n",
    "                              merge_mode='sum', name=('bi_lstm' + str(i+1)))(x)\n",
    "\n",
    "    # 1 fully connected layer DNN ReLu with default 20% dropout\n",
    "    x = TimeDistributed(Dense(units=units, kernel_initializer=kernel_init_dense, bias_initializer=bias_init_dense,\n",
    "                              activation='relu'), name='fc_4')(x)\n",
    "    x = TimeDistributed(Dropout(dropout), name='dropout_4')(x)\n",
    "\n",
    "    # Output layer with softmax\n",
    "    y_pred = TimeDistributed(Dense(units=output_dim, kernel_initializer=kernel_init_dense,\n",
    "                                   bias_initializer=bias_init_dense, activation='softmax'), name='softmax')(x)\n",
    "\n",
    "    # ---- CTC ----\n",
    "    # y_input layers (transcription data) for CTC loss\n",
    "    labels = Input(name='the_labels', shape=[None], dtype=dtype)       # transcription data (batch_size * y_seq_size)\n",
    "    input_length = Input(name='input_length', shape=[1], dtype=dtype)  # unpadded len of all x_sequences in batch\n",
    "    label_length = Input(name='label_length', shape=[1], dtype=dtype)  # unpadded len of all y_sequences in batch\n",
    "\n",
    "    # Lambda layer with ctc_loss function due to Keras not supporting CTC layers\n",
    "    loss_out = Lambda(function=ctc_lambda_func, name='ctc', output_shape=(1,))(\n",
    "                      [y_pred, labels, input_length, label_length])\n",
    "\n",
    "    network_model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out)\n",
    "\n",
    "    return network_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 255.88it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 2182.19it/s]\n",
      "loading and padding mfcc features:   0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 238.23it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 2311.27it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 404.24it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 2430.12it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 493.23it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 3009.57it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 418.47it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 3035.16it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 444.34it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 2644.53it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 619.01it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 3265.96it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 530.47it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 3228.64it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 361.05it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1699.65it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 411.07it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 2756.69it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 367.37it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1792.68it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 432.58it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1686.62it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 153.18it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1667.55it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 160.23it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1296.26it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 181.88it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1570.20it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 145.80it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1820.81it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 149.16it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1888.74it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 205.30it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1667.65it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 170.63it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1665.01it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 191.61it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1777.29it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 215.94it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 2053.26it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 267.62it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 2276.38it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 237.81it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1636.62it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 236.96it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1697.28it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 430.77it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 3950.25it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 228.44it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1904.66it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 209.29it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1896.45it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 219.93it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1806.55it/s]\n",
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 211.53it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 1854.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 90s - loss: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading and padding mfcc features:  56%|█████▋    | 18/32 [00:00<00:00, 174.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading and padding mfcc features: 100%|██████████| 32/32 [00:00<00:00, 152.83it/s]\n",
      "loading and padding labels: 100%|██████████| 32/32 [00:00<00:00, 2544.17it/s]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Not enough time for target transition sequence (required: 678, available: 641)2You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\n\t [[{{node ctc_9/CTCLoss}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-8e2bf2fb5a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_train_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Not enough time for target transition sequence (required: 678, available: 641)2You can turn this error into a warning by using the flag ignore_longer_outputs_than_inputs\n\t [[{{node ctc_9/CTCLoss}}]]"
     ]
    }
   ],
   "source": [
    "loss = {'ctc': lambda y_true, y_pred: y_pred}\n",
    "training_generator = data_gen\n",
    "#model = deep_rnn(units=256, input_dim=26, output_dim=29, dropout=0.2, numb_of_dense=3, n_layers=3)\n",
    "model = blstm(units=256, input_dim=26, output_dim=29, dropout=0.2, numb_of_dense=1, cudnn=False, n_layers=1)\n",
    "model_train_params = {'generator': training_generator,\n",
    "                      'epochs': 4,\n",
    "                      'verbose': 2,\n",
    "                      #'validation_data': validation_generator,\n",
    "                      'workers': 1,\n",
    "                      'shuffle': shuffle}\n",
    "\n",
    "optimizer = Adam(lr=0.0001, epsilon=1e-8, clipnorm=2.0)\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit_generator(**model_train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
