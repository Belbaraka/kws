{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASR based keyword spotting system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present in what follow a keyword spotting system solely based on an ASR engine. The pretrained model used can be found [here](http://zamia-speech.org/asr/). It has been trained on ~ **1500 hours** of speech (tedlium3, librispeech, voxforge and other open source datasets) and acheives **8.84% WER**. For more details check *Zamia*'s [release post.](https://goofy.zamia.org/lm/2019/06/20/1500-Hours-160k-Words-English-Zamia-Speech-Models-Released.html) The KWS is straightforward; the user provides a wav file sampled at **16kHz**, the ASR engine performs the speech to text decoding, and finally the keywords are searched in the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps (first time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the steps in the following order to be able to run the keywords spotting system defined below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the pretrained model and uncompress it (**500MB** uncompressed)\n",
    "- `wget https://goofy.zamia.org/zamia-speech/asr-models/kaldi-generic-en-tdnn_f-r20190609.tar.xz`\n",
    "- `tar xf kaldi-generic-en-tdnn_f-r20190609.tar.xz`\n",
    "\n",
    "Git clone repo and move pretrained model in cloned repo\n",
    "- `git clone https://gitlab.com/SpeechMasterStudents/kws` and create folders `model` and `transcriptions` in `kws/asr_kws/kaldi-generic-en-tdnn_f-r20190609/v1/`\n",
    "- copy content of `kaldi-generic-en-tdnn_f-r20190609/model` (untared file) in `kws/asr_kws/kaldi-generic-en-tdnn_f-r20190609/v1/model/` (repo)\n",
    "\n",
    "Upload your audio *.wav* files in `input/audio`, create files `transcriptions/spk2utt` and `transcriptions/wav.scp` by running function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def prepare_files(path2audio='input/audio/', path2files='transcriptions/', path_in_docker='/opt/kaldi/egs/alibel_model/v1/input/audio/'):\n",
    "    '''\n",
    "    Creates files wav.scp and  spk2utt\n",
    "    - wav.scp : a 2 columns file, left utterance_id , right path to audio file inside docker image\n",
    "    - spk2utt : a 2 columns file, left speaker_id, right utterance_id\n",
    "    We assume that each audio file represents one utterance and that speaker_id is different across audio files.\n",
    "    \n",
    "    Args:\n",
    "    path2audio: path to .wav audio files in local.\n",
    "    path2files: path to the transcriptions folder \n",
    "    path_in_docker: path to .wav audio files inside docker image (replace `alibel_model` with the name of the folder you created)\n",
    "\n",
    "    '''\n",
    "    # list all audio files \n",
    "    filenames = [f for f in listdir(path2audio) if isfile(join(path2audio, f)) and not f.startswith('.')]\n",
    "\n",
    "    # prepare wav.scp file\n",
    "    with open(join(path2files, 'wav.scp'), mode='w+') as fp:\n",
    "        for i, filename in enumerate(filenames):\n",
    "            utt_id = filename.split('.wav')[0] + '_utt' + str(i)\n",
    "            fp.write(utt_id + ' ' + join(path_in_docker, filename) + '\\n')\n",
    "    \n",
    "    print('File wav.scp created in ' + join(path2files, 'wav.scp'))        \n",
    "\n",
    "    # prepare spk2utt file\n",
    "    with open(join(path2files, 'spk2utt'), mode='w+') as fp:\n",
    "        for i, filename in enumerate(filenames):\n",
    "            utt_id = filename.split('.wav')[0] + '_utt' + str(i)\n",
    "            spk_id = 'speaker_' + str(i)\n",
    "            fp.write(spk_id + ' ' + utt_id + '\\n')\n",
    "            \n",
    "    print('File spk2utt created in ' + join(path2files, 'spk2utt'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File wav.scp created in transcriptions/wav.scp\n",
      "File spk2utt created in transcriptions/spk2utt\n"
     ]
    }
   ],
   "source": [
    "prepare_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download kaldi's docker image (cpu based)\n",
    "- `docker pull kaldiasr/kaldi`\n",
    "- run image and create new folder (eg. `alibel_model`) in `opt/kaldi/egs/` \n",
    "\n",
    "Save changes and stop container \n",
    "- `docker commit <container_id> kaldiasr/kaldi:latest`\n",
    "- `docker stop <container_id>`\n",
    "\n",
    "Run newly saved image and attach repo to perform decoding\n",
    "- `docker run -it -v ~/kws/asr_kws/kaldi-generic-en-tdnn_f-r20190609:/opt/kaldi/egs/alibel_model kaldiasr/kaldi:latest`\n",
    "- `cd` to `egs/alibel_model/v1` and run `./decode.sh`\n",
    "\n",
    "Transcriptions can be found under `transcriptions/transcribed_speech.txt` \n",
    "\n",
    "Run function `kws()` defined below to search for desired keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyword spotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kws(keywords, path2transciptions='transcriptions/transcribed_speech.txt'):\n",
    "    '''\n",
    "    Args:\n",
    "    keywords: customizable list of keywords.\n",
    "    path2transciption: path to the transcription file (ie. path to file `transcribed_speech.txt`)\n",
    "\n",
    "    Returns:\n",
    "    Dict, {keyword: number_of_times_spotted}\n",
    "    '''\n",
    "    \n",
    "    kw_dict = {}\n",
    "    # Initialize keyword dictionary\n",
    "    for kw in keywords:\n",
    "        kw_dict[kw] = 0\n",
    "    \n",
    "    utterances_dict = {} # Dict with elements (utterance_id, transcription)\n",
    "    with open(path2transciptions) as fp:\n",
    "        for line in fp:\n",
    "            utt_id, transcription = line.split(' ', 1)\n",
    "            for kw in keywords:\n",
    "                if kw in transcription:\n",
    "                    kw_dict[kw] += 1\n",
    "            utterances_dict[utt_id] = transcription\n",
    "    \n",
    "    print('ASR based keyword spotting results for the keywords provided :\\n')\n",
    "    print(kw_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASR based keyword spotting results for the keywords provided :\n",
      "\n",
      "{'learn': 1, 'protest': 2, 'chief': 1}\n"
     ]
    }
   ],
   "source": [
    "kws(keywords=['learn', 'protest', 'chief'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps (any other time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Upload desired audio files in `input/audio`. Note that audio files must be sampled at **16kHz** and must be **less than 20 seconds long**.\n",
    "- Create files `wav.scp` and `spk2utt`: `python3 prepare_files.py --path2audio='input/audio/' --path2files='transcriptions/' --path_in_docker='/opt/kaldi/egs/alibel_model/v1/input/audio/'`\n",
    "- Launch docker image and attach repo to it: `docker run -it -v ~/kws/asr_kws/kaldi-generic-en-tdnn_f-r20190609:/opt/kaldi/egs/alibel_model kaldiasr/kaldi:latest`\n",
    "- Run `decoding.sh` script: `cd egs/alibel_model/v1` and `./decode.sh`\n",
    "- Run keyword spotting system: `python3 asr_kws.py --keywords 'keyword_1' 'keyword_2' --path2transcription='transcriptions/transcribed_speech.txt'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What to do next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create an evaluation dataset to set a baseline score for this method\n",
    "- Depending on the score, investigate whether or not an end2end approach (**ASR-free**) would be better suited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
