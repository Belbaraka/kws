{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re\n",
    "from itertools import islice \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from python_speech_features import mfcc\n",
    "import scipy.io.wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['up', 'down', 'left', 'right']\n",
    "non_keywords = ['happy', 'bed', 'bird', 'cat', 'dog', 'marvin', 'sheila', 'house', 'tree', 'wow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get keyword filename of audio samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath(\"Datasets/google_dataset/\")\n",
    "filenames = []\n",
    "\n",
    "for w in (keywords + non_keywords):\n",
    "    current_path = os.path.join(path, w) \n",
    "    for _, _, files in os.walk(current_path):\n",
    "        for file in files:\n",
    "            filenames.append(os.path.join(current_path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WAVS_PER_CLASS = 2**27 - 1  # ~134M\n",
    "\n",
    "def which_set(filename, validation_percentage, testing_percentage):\n",
    "    \"\"\"Determines which data partition the file should belong to.\n",
    "\n",
    "    We want to keep files in the same training, validation, or testing sets even\n",
    "    if new ones are added over time. This makes it less likely that testing\n",
    "    samples will accidentally be reused in training when long runs are restarted\n",
    "    for example. To keep this stability, a hash of the filename is taken and used\n",
    "    to determine which set it should belong to. This determination only depends on\n",
    "    the name and the set proportions, so it won't change as other files are added.\n",
    "\n",
    "    It's also useful to associate particular files as related (for example words\n",
    "    spoken by the same person), so anything after '_nohash_' in a filename is\n",
    "    ignored for set determination. This ensures that 'bobby_nohash_0.wav' and\n",
    "    'bobby_nohash_1.wav' are always in the same set, for example.\n",
    "\n",
    "    Args:\n",
    "    filename: File path of the data sample.\n",
    "    validation_percentage: How much of the data set to use for validation.\n",
    "    testing_percentage: How much of the data set to use for testing.\n",
    "\n",
    "    Returns:\n",
    "    String, one of 'training', 'validation', or 'testing'.\n",
    "    \"\"\"\n",
    "    base_name = os.path.basename(filename)\n",
    "    # We want to ignore anything after '_nohash_' in the file name when\n",
    "    # deciding which set to put a wav in, so the data set creator has a way of\n",
    "    # grouping wavs that are close variations of each other.\n",
    "    hash_name = re.sub(r'_nohash_.*$', '', base_name).encode('utf-8')\n",
    "    # This looks a bit magical, but we need to decide whether this file should\n",
    "    # go into the training, testing, or validation sets, and we want to keep\n",
    "    # existing files in the same set even if more files are subsequently\n",
    "    # added.\n",
    "    # To do that, we need a stable way of deciding based on just the file name\n",
    "    # itself, so we do a hash of that and then use that to generate a\n",
    "    # probability value that we use to assign it.\n",
    "    hash_name_hashed = hashlib.sha1(hash_name).hexdigest()\n",
    "    percentage_hash = ((int(hash_name_hashed, 16) %\n",
    "                      (MAX_NUM_WAVS_PER_CLASS + 1)) *\n",
    "                     (100.0 / MAX_NUM_WAVS_PER_CLASS))\n",
    "    if percentage_hash < validation_percentage:\n",
    "        result = 'validation'\n",
    "    elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "        result = 'testing'\n",
    "    else:\n",
    "        result = 'training'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'testing'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_set(random.choice(filenames), validation_percentage=10, testing_percentage=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mfcc(signal, num_features=40): \n",
    "\n",
    "    features = mfcc(signal, samplerate=16000, winlen=0.030, winstep=0.01, numcep=num_features, \n",
    "                         lowfreq=20, highfreq=4000, appendEnergy=False, nfilt=num_features)\n",
    "    #features = np.mean(features, axis=0).reshape(1,-1)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/aimlx/Datasets/google_dataset/up/b7a0754f_nohash_4.wav',\n",
       " '/aimlx/Datasets/google_dataset/up/748cb308_nohash_0.wav',\n",
       " '/aimlx/Datasets/google_dataset/up/e7334395_nohash_0.wav',\n",
       " '/aimlx/Datasets/google_dataset/up/4f781a59_nohash_1.wav',\n",
       " '/aimlx/Datasets/google_dataset/up/cd8b1781_nohash_0.wav']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, sig = wav.read(random.choice(filenames))\n",
    "feats = compute_mfcc(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 40)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = {}\n",
    "for file in tqdm(filenames):\n",
    "    fs, signal = wav.read(file)\n",
    "    features = compute_mfcc(signal, fs)\n",
    "    #features = mfcc(signal, samplerate=16000, winlen=0.030, winstep=0.01, numcep=40, \n",
    "    #                     lowfreq=20, highfreq=4000, appendEnergy=False, nfilt=40)\n",
    "    if features.shape[0] in count.keys():\n",
    "        count[features.shape[0]] += 1\n",
    "    else:\n",
    "        count[features.shape[0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(count.keys(), count.values(), 1.0, color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_negative_samples(neg_filenames, validation_neg_percentage, label):\n",
    "    '''\n",
    "    Generates training and validation sets for the negative samples \n",
    "    '''\n",
    "    neg_feats = list(map(lambda x: (np.load(x, allow_pickle=False), label), neg_filenames))\n",
    "    random.shuffle(neg_feats)\n",
    "\n",
    "    neg_size = len(neg_feats)\n",
    "    nb_validation = int(neg_size * (validation_neg_percentage / 100))\n",
    "    nb_training = neg_size - nb_validation\n",
    "    \n",
    "    split_list = [nb_training, nb_validation] \n",
    "    \n",
    "    temp = iter(neg_feats) \n",
    "    splits = [list(islice(temp, 0, size)) for size in split_list ]\n",
    "    return splits[0], splits[1]\n",
    "\n",
    "\n",
    "def generate_sets(filenames, neg_filenames, validation_percentage=10, testing_percentage=10, validation_neg_percentage=20):\n",
    "    '''\n",
    "    each data sample in the tuple (features, label)\n",
    "    '''\n",
    "    \n",
    "    non_keywords_label = len(keywords)\n",
    "\n",
    "    training, validation, testing = [], [], []\n",
    "    min_nb_frames = 98\n",
    "    for filename in tqdm(filenames):\n",
    "        _, signal = wav.read(filename)\n",
    "        feats = compute_mfcc(signal)\n",
    "        \n",
    "        if feats.shape[0] < min_nb_frames:\n",
    "            continue\n",
    "        kw = filename.split('/')[-2]\n",
    "        if kw in keywords:\n",
    "            label = keywords.index(kw)\n",
    "        else:\n",
    "            label = non_keywords_label\n",
    "            \n",
    "        grp = which_set(filename, validation_percentage, testing_percentage)\n",
    "        \n",
    "        if grp is 'training':\n",
    "            training.append((feats, label))\n",
    "        elif grp is 'validation':\n",
    "            validation.append((feats, label))\n",
    "        else:\n",
    "            testing.append((feats, label))\n",
    "            \n",
    "    training_neg, validation_neg = load_negative_samples(neg_filenames, validation_neg_percentage, non_keywords_label)\n",
    "    \n",
    "    training.extend(training_neg)\n",
    "    validation.extend(validation_neg)\n",
    "    \n",
    "    return training, validation, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath(\"Datasets/negative_samples/\")\n",
    "neg_filenames = []\n",
    "\n",
    "for _, _, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.endswith('.npy'):\n",
    "            neg_filenames.append(os.path.join(path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26827/26827 [00:57<00:00, 470.14it/s]\n"
     ]
    }
   ],
   "source": [
    "training, validation, testing = generate_sets(filenames, neg_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(grp):\n",
    "    X, y = zip(*grp)\n",
    "    X = list(map(lambda x: x.reshape(98, 40, 1), X))\n",
    "    return np.array(X).reshape(-1, 98, 40, 1), np.array(y).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, AveragePooling2D, Dense, Flatten, Input, Add, Lambda\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_net():\n",
    "    \n",
    "    input_data = Input(shape=(98,40,1))\n",
    "    l = 0\n",
    "    for i in range(6):\n",
    "        if i == 0:\n",
    "            x = Conv2D(7, kernel_size=(3,3), activation='relu', data_format='channels_last', \n",
    "                       padding='same', kernel_initializer='glorot_uniform')(input_data)\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "            l += 1\n",
    "            x = Conv2D(7, kernel_size=(3,3), activation='relu', data_format='channels_last', \n",
    "                       padding='same', kernel_initializer='glorot_uniform', dilation_rate=int(math.pow(2, np.floor(l/3))))(x)\n",
    "            l += 1\n",
    "            x = BatchNormalization(axis=-1)(x)\n",
    "        else:\n",
    "            y = Conv2D(7, kernel_size=(3,3), activation='relu', data_format='channels_last', \n",
    "                       padding='same', kernel_initializer='glorot_uniform', dilation_rate=int(math.pow(2, np.floor(l/3))))(x)\n",
    "            y = BatchNormalization(axis=-1)(y)\n",
    "            l += 1\n",
    "            y = Conv2D(7, kernel_size=(3,3), activation='relu', data_format='channels_last', \n",
    "                       padding='same', kernel_initializer='glorot_uniform', dilation_rate=int(math.pow(2, np.floor(l/3))))(y)\n",
    "            l += 1\n",
    "            y = BatchNormalization(axis=-1)(y)\n",
    "\n",
    "            y = Add()([y, x])\n",
    "            x = Lambda(lambda x: x)(y)\n",
    "    \n",
    "    x = AveragePooling2D(pool_size=(2,2),data_format='channels_last')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=len(keywords) + 1, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_data, outputs=x) \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def dnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(5,5), activation='relu', input_shape=(98, 40, 1), data_format='channels_last')) \n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(5,5), activation='relu')) \n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=(5,5), activation='relu')) \n",
    "    model.add(BatchNormalization(axis=-1))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dense(units=len(keywords) + 1, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = get_X_y(training)\n",
    "X_validation, y_validation = get_X_y(validation)\n",
    "y_train, y_validation = to_categorical(y_train), to_categorical(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 94, 36, 32)        832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 94, 36, 32)        128       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 47, 18, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 43, 14, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 43, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_5 (Average (None, 21, 7, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 17, 3, 128)        204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 17, 3, 128)        512       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_6 (Average (None, 8, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 389,765\n",
      "Trainable params: 389,317\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = dnn_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 58273 samples, validate on 12284 samples\n",
      "Epoch 1/3\n",
      "58273/58273 [==============================] - 204s 3ms/step - loss: 0.2194 - acc: 0.9310 - val_loss: 0.0859 - val_acc: 0.9732\n",
      "Epoch 2/3\n",
      "58273/58273 [==============================] - 203s 3ms/step - loss: 0.0963 - acc: 0.9683 - val_loss: 0.0617 - val_acc: 0.9796\n",
      "Epoch 3/3\n",
      "58273/58273 [==============================] - 200s 3ms/step - loss: 0.0689 - acc: 0.9769 - val_loss: 0.0406 - val_acc: 0.9872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7a9b080f60>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=20, epochs=3, verbose=1, validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = get_X_y(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2512/2512 [==============================] - 2s 614us/step\n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict_classes(X_test, verbose=1)\n",
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9187898089171974"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.9434713375796179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generates_frames(features, shift=5, frame_length=98, num_mffc=40):\n",
    "    frames = []\n",
    "    window_size = features.shape[0]\n",
    "    enough_samples = True\n",
    "    current_index = 0\n",
    "    \n",
    "    while enough_samples:\n",
    "        if current_index + frame_length < window_size:\n",
    "            frames.append(features[current_index: current_index + frame_length, :])\n",
    "            current_index += shift\n",
    "        else:\n",
    "            frames.append(features[-frame_length:,:])\n",
    "            enough_samples = False\n",
    "    return np.array(frames).reshape(-1, frame_length, num_mffc, 1)\n",
    "\n",
    "def compute_mfcc_frames(signal, shape=(98,40)):\n",
    "    features = mfcc(signal, samplerate=16000, winlen=0.030, winstep=0.01, numcep=shape[1], \n",
    "                         lowfreq=20, highfreq=4000, appendEnergy=False, nfilt=shape[1])\n",
    "    print(features.shape)\n",
    "    if features.shape[0] <= shape[0]:\n",
    "        nb_samples = shape[0] - features.shape[0]\n",
    "        features = np.concatenate((np.zeros((nb_samples, shape[1])), features), axis=0)\n",
    "        return features.reshape(1, shape[0], shape[1], 1)\n",
    "    else:\n",
    "        frames = generates_frames(features, shift=1, frame_length=shape[0], num_mffc=shape[1])\n",
    "        return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs, sig = wav.read('phrase1_down.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212, 40)\n"
     ]
    }
   ],
   "source": [
    "frames = compute_mfcc_frames(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 98, 40, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115/115 [==============================] - 0s 650us/step\n"
     ]
    }
   ],
   "source": [
    "#y_pred = model.predict_classes(frames, verbose=1)\n",
    "y_pred = model.predict(frames, verbose=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1,\n",
       "       1, 1, 1, 1, 4])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['up', 'down', 'left', 'right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
